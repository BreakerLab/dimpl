{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet for IGR Selection and BLAST Processing\n",
    "---\n",
    "Instructions: Run each cell one at a time following instructions in markdown headers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jovyan/work\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import tarfile\n",
    "import pickle\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import logging; logging.captureWarnings(True)\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from src.visualization.visualize import graph_genome, graph_layout\n",
    "from src.data.rfam_db import rfam_session, Genome\n",
    "from src.models.predict_model import process_blast\n",
    "from src.data.command_build import build_infernal_commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set name of the blast results tar.gz below:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tar file with the results from the blast analysis\n",
    "import_tar_name = \"data/import/Francisella_tularensis_GCA_000008985.1_selection_0.5_2.0_-2.0_blastdata.done.tar.gz\"\n",
    "# Assembly Accession (also the folder the genome's data will be stored in)\n",
    "assembly_acc = \"GCA_000008985.1\"\n",
    "# Selection name (also a subfolder where the data for the selection stored)\n",
    "selection_name = \"selection_0.5_2.0_-2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take files from tar.gz and place them in the proper locations in the data/interim folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/genomes/{}/{}\".format(assembly_acc, selection_name)\n",
    "\n",
    "def tar_subdir_members(tar, import_tar_name):\n",
    "    tar_foldername = re.sub(r'(\\.done)*\\.tar\\.gz','',import_tar_name.split('/')[-1]) + '/'\n",
    "    tar_foldername_length = len(tar_foldername)\n",
    "    for member in tar.getmembers():\n",
    "        if member.path.startswith(tar_foldername):\n",
    "            member.path = member.path[tar_foldername_length:]\n",
    "            yield member\n",
    "        \n",
    "with tarfile.open(import_tar_name, \"r:gz\") as tar:\n",
    "    tar.extractall(path=data_dir, members=tar_subdir_members(tar, import_tar_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild the selection using archived data in the interim folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of known IGRs included:   31 (88.6%)\n",
      "Number of unknown IGRs included: 108 (7.1%)\n",
      "Fold Enrichment:  9.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c8401ba05446f094adbe37939a36b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'hoverinfo': 'skip',\n",
       "              'marker': {'color': 'rgba(192,192,192,0.9)', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the appropriate genome   \n",
    "session = rfam_session()\n",
    "genome_list = session.query(Genome).filter(Genome.assembly_acc == assembly_acc).all()\n",
    "assert len(genome_list) == 1\n",
    "genome = genome_list[0]\n",
    "\n",
    "# Read in the annotated igr df from the files\n",
    "annotated_df = pd.read_csv(\"{}/data_files/annotated_igrs.csv\".format(data_dir), index_col=0)\n",
    "\n",
    "\n",
    "with open(\"{}/data_files/svmclf.pickle\".format(data_dir), 'rb') as svm_pickle_file:\n",
    "    svm_clf = pickle.loads(svm_pickle_file.read())\n",
    "\n",
    "selection = pd.Series(svm_clf.predict(annotated_df.loc[:, [\"gc\", \"log_length\"]]))\n",
    "\n",
    "scatter_plots = graph_genome(annotated_df, selection=selection)\n",
    "layout = graph_layout(genome)\n",
    "fig = go.FigureWidget(data=scatter_plots, layout=layout)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Process blast results\n",
    "---\n",
    "Identifies protein coding regions in the IGR, process_blast calculates an \"orf_score\" at each nucleotide position. \n",
    "\n",
    "This score starts at 0 at each nucleotide position and is increased by $s_i \\times w_p \\times w_h $ for each overlapping hit. Where \n",
    "\n",
    "* $s_i$ is the score_increment (default 2)\n",
    "* $w_p$ is the poor_score_weight (default 0.5) which is a penalty applied when a hit's blast score is less than the poor_blast_score (default 40).\n",
    "* $w_h$ is the hypothetical_weight (default 0.5) which is a penalty applied when a hit matches a hypothetical protein.\n",
    "\n",
    "All nucleotide positions of the IGR where the orf_score $>=$ orf_score_cutoff (default 4) are flagged for removal. Any remaining contiguous IGR portions have their lengths and GC-contents recalculated and checked to see if they still fall in the selection boundaries. \n",
    "\n",
    "The decision boundary can be made more flexible by decreasing the svm_decision_cutoff from the default value of 0.0 to a slighly smaller number -0.3. The selection corresponding to this expanded selection boundary will be graphed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of known IGRs included:   32 (91.4%)\n",
      "Number of unknown IGRs included: 130 (8.6%)\n",
      "Fold Enrichment:  8.56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74023bc5d9c440aa822c75124f406412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'hoverinfo': 'skip',\n",
       "              'marker': {'color': 'rgba(192,192,192,0.9)', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_decision_cutoff=-0.3\n",
    "\n",
    "fasta_dir = data_dir + '/igr_fastas'\n",
    "xml_dir = data_dir + '/blast_xml'\n",
    "\n",
    "process_blast(fasta_dir, xml_dir, svm_clf, poor_blast_score=40, poor_score_weight=0.5, \n",
    "              hypothetical_weight=0.5, orf_score_cutoff=4, score_increment=2, \n",
    "              svm_decision_cutoff=-0.3)\n",
    "expanded_selection = svm_clf.decision_function(annotated_df[[\"gc\", \"log_length\"]]) > svm_decision_cutoff\n",
    "\n",
    "expanded_scatter_plots = graph_genome(annotated_df, selection=expanded_selection)\n",
    "expanded_layout = graph_layout(genome)\n",
    "expanded_layout.title.text = layout.title.text + \" (w/ decision cutoff > {})\".format(svm_decision_cutoff)\n",
    "expanded_fig = go.FigureWidget(data=expanded_scatter_plots, layout=expanded_layout)\n",
    "expanded_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build Data and Script tarfiles for Analysis on Cluster\n",
    "---\n",
    "`step_dir` refers to the subdirectory where the sto files and scripts will be written for analysis. The script then creates a tarfile in the data/export directory where it can be transferred to a high performance computing cluster to execute the computationally-intensive homology searches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tarfle created: /home/jovyan/work/data/export/Francisella_tularensis_GCA_000008985.1_selection_0.5_2.0_-2.0_infernal_step1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "step_dir=\"infernal_step1\"\n",
    "\n",
    "build_infernal_commands(data_dir,step_dir, no_secondary_structure=True)\n",
    "\n",
    "tarfilename=\"{}_{}_{}_{}\".format('_'.join(genome.scientific_name.split(' ')[0:2]), genome.assembly_acc, selection_name, step_dir)\n",
    "with tarfile.open(\"data/export/{}.tar.gz\".format(tarfilename), \"w:gz\") as tar:\n",
    "    tar.add(data_dir, arcname=tarfilename)\n",
    "    print(\"\\nTarfle created:\",tar.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Transfer Data Tarfile and Run Infernal Script\n",
    "---\n",
    "Move Tarfile to your high-performance cluster. Tarfile is located in data/export.\n",
    "If you typically log into cluster using `ssh`, you'll be able to use `scp` to do the file transfer. Example command: `scp /path/to/dimpl/data/export/tarfilename.tar.gz netid@farnam.hpc.yale.edu:~/project/wherever`.\n",
    "\n",
    "Untar the uploaded file by using the command `tar xzvf tarfilename`. Remove tarfile using `rm tarfilename.tar.gz` (unpacked files will remain).\n",
    "\n",
    "Run the Infernal script in the newly extracted folder by entering `./infernal_step1_run.sh` into the terminal.\n",
    "\n",
    "You can monitor completion of the analysis using the command `squeue -u username` to see running tasks. (PD = pending, R = running)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create and Transfer Results Tarfile\n",
    "---\n",
    "After the all of the jobs complete, run `./make_tar.sh` in the same folder where you ran Infernal.  This will pack up the processed data into a new tarfile called `tarfilename.done.tar.gz`.  \n",
    "\n",
    "Move the tarfile back to this system and place it in the `data/import` folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
